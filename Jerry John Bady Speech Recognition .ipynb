{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554560cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4466822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jquin\\AppData\\Local\\Temp\\ipykernel_27212\\2759194993.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  transcript_df[\"Processed_Transcript\"] = transcript_df[\"Processed_Transcript\"].str.replace(\"[^\\w\\s]\", \"\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define path to the folder containing transcript files\n",
    "transcript_folder = \"C:/Users/jquin/Downloads/speech recognition/akan audio\"\n",
    "\n",
    "# Initialize empty lists to store transcript data\n",
    "transcripts = []\n",
    "\n",
    "# Iterate over the transcript files in the folder\n",
    "for filename in os.listdir(transcript_folder):\n",
    "    if filename.endswith(\".txt\"):  # Assuming transcript files are in .txt format\n",
    "        file_path = os.path.join(transcript_folder, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            transcript_text = file.read()\n",
    "            transcripts.append(transcript_text)\n",
    "\n",
    "# Convert transcript data to DataFrame\n",
    "transcript_df = pd.DataFrame(transcripts, columns=[\"Transcript\"])\n",
    "\n",
    "# Preprocess text data (cleaning, normalization, tokenization, etc.)\n",
    "transcript_df[\"Processed_Transcript\"] = transcript_df[\"Transcript\"].str.lower()\n",
    "transcript_df[\"Processed_Transcript\"] = transcript_df[\"Processed_Transcript\"].str.replace(\"[^\\w\\s]\", \"\")\n",
    "\n",
    "# Tokenization: Split each transcript into individual words\n",
    "tokenized_transcripts = transcript_df[\"Processed_Transcript\"].apply(lambda x: x.split())\n",
    "\n",
    "# Flatten the list of lists to create a vocabulary\n",
    "vocabulary = sorted(set(word for transcript in tokenized_transcripts for word in transcript))\n",
    "\n",
    "# Create a dictionary to map words to indices\n",
    "word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
    "\n",
    "# Convert tokenized transcripts to numerical representations using one-hot encoding\n",
    "def one_hot_encode(transcript, word_to_index):\n",
    "    encoded_transcript = np.zeros(len(word_to_index))\n",
    "    for word in transcript:\n",
    "        if word in word_to_index:\n",
    "            encoded_transcript[word_to_index[word]] = 1\n",
    "    return encoded_transcript\n",
    "\n",
    "# Encode each transcript in the list\n",
    "encoded_transcripts = tokenized_transcripts.apply(lambda x: one_hot_encode(x, word_to_index))\n",
    "\n",
    "# Define paths to the original transcript folder\n",
    "transcript_folder = \"C:/Users/jquin/Downloads/speech recognition/transcript\"\n",
    "train_folder = \"C:/Users/jquin/Downloads/speech recognition/training\"\n",
    "val_folder = \"C:/Users/jquin/Downloads/speech recognition/evaluation\"\n",
    "test_folder = \"C:/Usersjquin/Downloads/speech recognition/testing\" \n",
    "\n",
    "# Create directories for train, validation, and test sets if they don't exist\n",
    "for folder in [train_folder, val_folder, test_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Iterate over the files in the transcript folder\n",
    "file_list = os.listdir(transcript_folder)\n",
    "random.shuffle(file_list)\n",
    "\n",
    "# Split the file list into train, validation, and test sets\n",
    "num_files = len(file_list)\n",
    "num_train = int(0.7 * num_files)\n",
    "num_val = int(0.15 * num_files)\n",
    "\n",
    "train_files = file_list[:num_train]\n",
    "val_files = file_list[num_train:num_train + num_val]\n",
    "test_files = file_list[num_train + num_val:]\n",
    "\n",
    "# Move files to their respective folders\n",
    "for file in train_files:\n",
    "    shutil.move(os.path.join(transcript_folder, file), os.path.join(train_folder, file))\n",
    "for file in val_files:\n",
    "    shutil.move(os.path.join(transcript_folder, file), os.path.join(val_folder, file))\n",
    "for file in test_files:\n",
    "    shutil.move(os.path.join(transcript_folder, file), os.path.join(test_folder, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "499971ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/jquin/Downloads/speech recognition/akan audio\\\\_image_0012_u186_1_1679885779700.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;66;03m#transcript_path = os.path.join(train_transcript_folder, audio_file.replace(\".mp3\", \".txt\"))\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         audio \u001b[38;5;241m=\u001b[39m load_audio(audio_path)\n\u001b[1;32m---> 28\u001b[0m         transcript \u001b[38;5;241m=\u001b[39m load_transcript(transcript_path)\n\u001b[0;32m     29\u001b[0m         train_data\u001b[38;5;241m.\u001b[39mappend((audio, transcript))\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Example of how to access audio and transcript from train_data\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[35], line 13\u001b[0m, in \u001b[0;36mload_transcript\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_transcript\u001b[39m(file_path):\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     14\u001b[0m         transcript_text \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transcript_text\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/jquin/Downloads/speech recognition/akan audio\\\\_image_0012_u186_1_1679885779700.txt'"
     ]
    }
   ],
   "source": [
    "# Load the data and preprocess it for training\n",
    "# Define the training, validation, and testing datasets (placeholders, replace with your actual data)\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Example function to load audio recordings\n",
    "def load_audio(file_path, sample_rate=16000):\n",
    "    audio, _ = librosa.load(file_path, sr=sample_rate)\n",
    "    return audio\n",
    "\n",
    "# Example function to load transcripts\n",
    "def load_transcript(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        transcript_text = file.read()\n",
    "    return transcript_text\n",
    "\n",
    "# Define paths to the training audio and transcript folders\n",
    "train_audio_folder = \"C:/Users/jquin/Downloads/speech recognition/akan audio\"\n",
    "train_transcript_folder = \"C:/Users/jquin/Downloads/speech recognition/akan audio\"\n",
    "\n",
    "# Iterate over the files in the training audio folder\n",
    "train_data = []\n",
    "for audio_file in os.listdir(train_audio_folder):\n",
    "    if audio_file.endswith(\".mp3\"):  # Assuming audio files are in .wav format\n",
    "        audio_path = os.path.join(train_audio_folder, audio_file)\n",
    "        transcript_path = os.path.join(train_transcript_folder, audio_file.replace(\".mp3\", \".txt\"))\n",
    "        audio = load_audio(audio_path)\n",
    "        transcript = load_transcript(transcript_path)\n",
    "        train_data.append((audio, transcript))\n",
    "\n",
    "# Example of how to access audio and transcript from train_data\n",
    "sample_audio, sample_transcript = train_data[0]\n",
    "\n",
    "\n",
    "# Define constants\n",
    "max_seq_length = 3  # Adjust as needed\n",
    "batch_size = 1  # Adjust as needed\n",
    "\n",
    "# Define the model architecture\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=len(vocabulary), output_dim=100, input_length=max_seq_length),\n",
    "    layers.LSTM(units=128, return_sequences=True),\n",
    "    layers.TimeDistributed(layers.Dense(len(vocabulary), activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, train_labels,\n",
    "                    validation_data=(val_data, val_labels),\n",
    "                    epochs=10,  # Adjust as needed\n",
    "                    batch_size=batch_size)\n",
    "\n",
    "# Plot training and validation loss over epochs\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy over epochs\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "loss, accuracy = model.evaluate(test_data, test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"speech_recognition_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e813b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f154f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
